{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Binary Label Debiasing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXDHH6aKw1I6",
        "colab_type": "code",
        "outputId": "84072837-072e-47f4-f4b4-a3de49ff9d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"sudhasravanthy\"\n",
        "os.environ['KAGGLE_KEY'] = \"29298b9cb3cae563e590d179037f609a\"\n",
        "\n",
        "\n",
        "!kaggle datasets download -d devjyotichandra/glove6b50dtxt # api copied from kaggle"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove6b50dtxt.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTWcobg1xCpC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q '/content/glove6b50dtxt.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swWL5m2Nuas-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_vecs(glove_file):\n",
        "    with open(glove_file, 'r', encoding='UTF-8') as f:\n",
        "        words = set()\n",
        "        word_to_vec_map = {}\n",
        "\n",
        "        for line in f:\n",
        "            line = line.strip().split()\n",
        "            current_word = line[0]\n",
        "            words.add(current_word)\n",
        "            word_to_vec_map[current_word] = np.array(line[1:], dtype=np.float64)\n",
        "\n",
        "    return words, word_to_vec_map\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn9lvbW5yDgo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words, word_to_vec_map = read_vecs('/content/glove.6B.50d.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBI_DaEgyNco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_similarity(u, v):\n",
        "    \"\"\"\n",
        "    Cosine similarity reflects the degree of similariy between u and v\n",
        "\n",
        "    Arguments:\n",
        "        u -- a word vector of shape (n,)          \n",
        "        v -- a word vector of shape (n,)\n",
        "\n",
        "    Returns:\n",
        "        cosine_similarity -- the cosine similarity between u and v defined by the formula above.\n",
        "    \"\"\"\n",
        "\n",
        "    distance = 0.0\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # Compute the dot product between u and v (≈1 line)\n",
        "    dot = np.dot(u, v)\n",
        "    # Compute the L2 norm of u (≈1 line)\n",
        "    norm_u = np.sqrt(np.sum(np.square(u), axis=0))\n",
        "\n",
        "    # Compute the L2 norm of v (≈1 line)\n",
        "    norm_v = np.sqrt(np.sum(np.square(v), axis=0))\n",
        "    # Compute the cosine similarity defined by formula (1) (≈1 line)\n",
        "    cosine_similarity = dot/(norm_u * norm_v)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return cosine_similarity\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKRA2dq8yaaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def complete_analogy(word_a, word_b, word_c, word_to_vec_map):\n",
        "    \"\"\"\n",
        "    Performs the word analogy task as explained above: a is to b as c is to ____. \n",
        "\n",
        "    Arguments:\n",
        "    word_a -- a word, string\n",
        "    word_b -- a word, string\n",
        "    word_c -- a word, string\n",
        "    word_to_vec_map -- dictionary that maps words to their corresponding vectors. \n",
        "\n",
        "    Returns:\n",
        "    best_word --  the word such that v_b - v_a is close to v_best_word - v_c, as measured by cosine similarity\n",
        "    \"\"\"\n",
        "\n",
        "    # convert words to lower case\n",
        "    word_a, word_b, word_c = word_a.lower(), word_b.lower(), word_c.lower()\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # Get the word embeddings v_a, v_b and v_c (≈1-3 lines)\n",
        "    e_a, e_b, e_c = word_to_vec_map[word_a], word_to_vec_map[word_b], word_to_vec_map[word_c]\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    words = word_to_vec_map.keys()\n",
        "    max_cosine_sim = -100              # Initialize max_cosine_sim to a large negative number\n",
        "    best_word = None                   # Initialize best_word with None, it will help keep track of the word to output\n",
        "\n",
        "    # loop over the whole word vector set\n",
        "    for w in words:        \n",
        "        # to avoid best_word being one of the input words, pass on them.\n",
        "        if w in [word_a, word_b, word_c] :\n",
        "            continue\n",
        "        ### START CODE HERE ###\n",
        "        # Compute cosine similarity between the vector (e_b - e_a) and the vector ((w's vector representation) - e_c)  (≈1 line)\n",
        "        cosine_sim = cosine_similarity(e_b - e_a, word_to_vec_map[w] - e_c)\n",
        "        \n",
        "        # If the cosine_sim is more than the max_cosine_sim seen so far,\n",
        "            # then: set the new max_cosine_sim to the current cosine_sim and the best_word to the current word (≈3 lines)\n",
        "        if cosine_sim > max_cosine_sim:\n",
        "            max_cosine_sim = cosine_sim\n",
        "            best_word = w\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "    return best_word\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tfI0WPCy4Uq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def neutralize(word, g, word_to_vec_map):\n",
        "    \"\"\"\n",
        "    Removes the bias of \"word\" by projecting it on the space orthogonal 正交 to the bias axis. \n",
        "    This function ensures that gender neutral words are zero in the gender subspace.\n",
        "\n",
        "    Arguments:\n",
        "        word -- string indicating the word to debias\n",
        "        g -- numpy-array of shape (50,), corresponding to the bias axis (such as gender)\n",
        "        word_to_vec_map -- dictionary mapping words to their corresponding vectors.\n",
        "\n",
        "    Returns:\n",
        "        e_debiased -- neutralized word vector representation of the input \"word\"\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # Select word vector representation of \"word\". Use word_to_vec_map. (≈ 1 line)\n",
        "    e = word_to_vec_map[word]\n",
        "\n",
        "    # Compute e_biascomponent using the formula give above. (≈ 1 line)\n",
        "    e_biascomponent = (np.dot(e, g) * g)/np.dot(g, g)\n",
        "\n",
        "    # Neutralize e by substracting e_biascomponent from it \n",
        "    # e_debiased should be equal to its orthogonal projection. 应该等于它的正交投影(≈ 1 line)\n",
        "    e_debiased = e - e_biascomponent\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return e_debiased\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V912ZsAxzBuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def equalize(pair, bias_axis, word_to_vec_map):\n",
        "    \"\"\"\n",
        "    Debias gender specific words by following the equalize method described in the figure above.\n",
        "\n",
        "    Arguments:\n",
        "    pair -- pair of strings of gender specific words to debias, e.g. (\"actress\", \"actor\") \n",
        "    bias_axis -- numpy-array of shape (50,), vector corresponding to the bias axis, e.g. gender\n",
        "    word_to_vec_map -- dictionary mapping words to their corresponding vectors\n",
        "\n",
        "    Returns\n",
        "    e_1 -- word vector corresponding to the first word\n",
        "    e_2 -- word vector corresponding to the second word\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # Step 1: Select word vector representation of \"word\". Use word_to_vec_map. (≈ 2 lines)\n",
        "    w1, w2 = pair\n",
        "    e_w1, e_w2 = word_to_vec_map[w1], word_to_vec_map[w2]\n",
        "\n",
        "    # Step 2: Compute the mean of e_w1 and e_w2 (≈ 1 line)\n",
        "    mu = (e_w1+e_w2)/2\n",
        "\n",
        "    # Step 3: Compute the projections of mu over the bias axis and the orthogonal axis (≈ 2 lines)\n",
        "    mu_B = (np.dot(mu, bias_axis) * bias_axis)/np.dot(bias_axis, bias_axis)\n",
        "    mu_orth = mu - mu_B\n",
        "\n",
        "    # Step 4: Use equations (7) and (8) to compute e_w1B and e_w2B (≈2 lines)\n",
        "    e_w1B = (np.dot(e_w1, bias_axis)* bias_axis)/np.dot(bias_axis, bias_axis)\n",
        "    e_w2B = (np.dot(e_w2, bias_axis)* bias_axis)/np.dot(bias_axis, bias_axis)\n",
        "\n",
        "    # Step 5: Adjust the Bias part of e_w1B and e_w2B using the formulas (9) and (10) given above (≈2 lines)\n",
        "    corrected_e_w1B = np.sqrt(np.abs(1 - np.dot(mu_orth, mu_orth)))*(e_w1B - mu_B)/np.linalg.norm(e_w1 - mu_orth - mu_B)\n",
        "    corrected_e_w2B = np.sqrt(np.abs(1 - np.dot(mu_orth, mu_orth)))*(e_w2B - mu_B)/np.linalg.norm(e_w2 - mu_orth - mu_B)\n",
        "\n",
        "    # Step 6: Debias by equalizing e1 and e2 to the sum of their corrected projections (≈2 lines)\n",
        "    e1 = corrected_e_w1B + mu_orth\n",
        "    e2 = corrected_e_w2B + mu_orth\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return e1, e2\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N74vGBX052IP",
        "colab_type": "text"
      },
      "source": [
        "Gender Debiasing - Neutralizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrBi2x1i5u6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#words = ['receptionist', 'scientist', 'professor', 'lawyer', 'entrepreneur']\n",
        "words_observations = ['teacher', 'wrestler', 'athlete', 'paralegal', 'tycoon']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cq2ltdbp6V4C",
        "colab_type": "code",
        "outputId": "9854a313-4aef-49c6-a969-55e0ed96fb34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('before Debiasing')\n",
        "for word in words_observations:\n",
        "  print('Cosine Similarity of word ' + word + ' and g is: ' + str(cosine_similarity(word_to_vec_map[word], word_to_vec_map['woman'] - word_to_vec_map['man'])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before Debiasing\n",
            "Cosine Similarity of word teacher and g is: 0.17920923431825664\n",
            "Cosine Similarity of word wrestler and g is: -0.038690746063892216\n",
            "Cosine Similarity of word athlete and g is: 0.06914822891263249\n",
            "Cosine Similarity of word paralegal and g is: 0.3014173349954554\n",
            "Cosine Similarity of word tycoon and g is: -0.19188610612411847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0yrN3eT694Y",
        "colab_type": "code",
        "outputId": "6e6bc489-d5fd-4d90-a299-c6deb94f4e23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('after Debiasing')\n",
        "#words = ['teacher', 'wrestler', 'athlete', 'paralegal', 'tycoon']\n",
        "for word in words_observations:\n",
        "  e1 = neutralize(word, word_to_vec_map['woman'] - word_to_vec_map['man'], word_to_vec_map)\n",
        "  word_to_vec_map[word] = e1  \n",
        "  print('Cosine Similarity of word ' + word + ' and g is: ' + str(cosine_similarity(word_to_vec_map[word], word_to_vec_map['woman'] - word_to_vec_map['man'])))\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "after Debiasing\n",
            "Cosine Similarity of word teacher and g is: -4.238781742793106e-18\n",
            "Cosine Similarity of word wrestler and g is: -4.336719188638501e-18\n",
            "Cosine Similarity of word athlete and g is: -2.4978280272612416e-17\n",
            "Cosine Similarity of word paralegal and g is: -2.2433671065701604e-17\n",
            "Cosine Similarity of word tycoon and g is: -6.877016649377774e-18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hnaFqzFBe4D",
        "colab_type": "text"
      },
      "source": [
        "Gender Debiasing - Equalizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_nQeTIVr4WA4",
        "colab": {}
      },
      "source": [
        "word_observations = ['master', 'businessman', 'doctor','policeman', 'salesman', 'engineer']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sOmtizNA4TXE",
        "outputId": "82749fa2-b34e-4dab-81bd-25b8fd5fa478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print('before Debiasing')\n",
        "for word in word_observations:\n",
        "  print('Gender Bias female word for ' + word + ' is: ' + complete_analogy('man', word, 'woman', word_to_vec_map))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before Debiasing\n",
            "Gender Bias female word for master is: diploma\n",
            "Gender Bias female word for businessman is: businesswoman\n",
            "Gender Bias female word for doctor is: nurse\n",
            "Gender Bias female word for policeman is: wounding\n",
            "Gender Bias female word for salesman is: saleswoman\n",
            "Gender Bias female word for engineer is: technician\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "apMbH9E74SnS",
        "outputId": "56d968a1-5f5d-4fcc-ef2a-8a4098f2ce7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "\n",
        "print('after Debiasing')\n",
        "words = [['master', 'mistress'], ['businessman', 'businesswoman'], ['doctor', 'gynecologist'], ['policeman', 'policewoman'], ['salesman', 'saleswoman'], ['engineer', 'architect']]\n",
        "for word in words:\n",
        "  e1, e2 = equalize((word[0], word[1]), word_to_vec_map['woman'] - word_to_vec_map['man'], word_to_vec_map)\n",
        "  word_to_vec_map[word[0]] = e1\n",
        "  word_to_vec_map[word[1]] = e2\n",
        "  print('Gender Bias female word for ' + word[0] + ' is: ' + complete_analogy('man', word[0], 'woman', word_to_vec_map))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "after Debiasing\n",
            "Gender Bias female word for master is: mistress\n",
            "Gender Bias female word for businessman is: businesswoman\n",
            "Gender Bias female word for doctor is: gynecologist\n",
            "Gender Bias female word for policeman is: policewoman\n",
            "Gender Bias female word for salesman is: saleswoman\n",
            "Gender Bias female word for engineer is: architect\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcPdGL9b5VJC",
        "colab_type": "text"
      },
      "source": [
        "Relations Debiasing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hRveU0BM5TW5",
        "colab": {}
      },
      "source": [
        "word_observations = ['he', 'his', 'son','male', 'boy', 'father', 'uncle', 'monastery', 'husband', 'Dad', 'Men', 'grandpa', 'grandson', 'uncle', 'brother']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b184e82c-87b2-4701-886f-825aea2f9066",
        "id": "k2x_pR2M5TW-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "print('before Debiasing')\n",
        "for word in word_observations:\n",
        "  print('Gender Bias female word for ' + word + ' is: ' + complete_analogy('man', word, 'woman', word_to_vec_map))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before Debiasing\n",
            "Gender Bias female word for he is: she\n",
            "Gender Bias female word for his is: her\n",
            "Gender Bias female word for son is: daughter\n",
            "Gender Bias female word for male is: female\n",
            "Gender Bias female word for boy is: girl\n",
            "Gender Bias female word for father is: daughter\n",
            "Gender Bias female word for uncle is: niece\n",
            "Gender Bias female word for monastery is: convent\n",
            "Gender Bias female word for husband is: wife\n",
            "Gender Bias female word for Dad is: mom\n",
            "Gender Bias female word for Men is: women\n",
            "Gender Bias female word for grandpa is: grandma\n",
            "Gender Bias female word for grandson is: granddaughter\n",
            "Gender Bias female word for uncle is: niece\n",
            "Gender Bias female word for brother is: daughter\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zHLaLuA67UK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_observations = ['brothers', 'brother', 'boyfriend', 'fatherhood', 'gentleman', 'grandfather', 'nephew', 'king', 'prince', 'schoolboy']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQxuaeY97hlZ",
        "colab_type": "code",
        "outputId": "a62476ad-0719-4100-a2b6-b05372833597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "print('before Debiasing')\n",
        "for word in word_observations:\n",
        "  print('Gender Bias female word for ' + word + ' is: ' + complete_analogy('man', word, 'woman', word_to_vec_map))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before Debiasing\n",
            "Gender Bias female word for brothers is: avett\n",
            "Gender Bias female word for brother is: daughter\n",
            "Gender Bias female word for boyfriend is: girlfriend\n",
            "Gender Bias female word for fatherhood is: motherhood\n",
            "Gender Bias female word for gentleman is: gentlewoman\n",
            "Gender Bias female word for grandfather is: granddaughter\n",
            "Gender Bias female word for nephew is: niece\n",
            "Gender Bias female word for king is: queen\n",
            "Gender Bias female word for prince is: princess\n",
            "Gender Bias female word for schoolboy is: 16-year-old\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f36033e7-44c8-4311-ef87-08ca7fe03023",
        "id": "xt5uAWGa5TXB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "\n",
        "print('after Debiasing')\n",
        "words = [['father', 'mother'], ['uncle', 'aunt'], ['brother', 'sister'], ['brothers', 'sisters'], ['grandfather', 'grandmother'], ['schoolboy', 'schoolgirl']]\n",
        "for word in words:\n",
        "  e1, e2 = equalize((word[0], word[1]), word_to_vec_map['woman'] - word_to_vec_map['man'], word_to_vec_map)\n",
        "  word_to_vec_map[word[0]] = e1\n",
        "  word_to_vec_map[word[1]] = e2\n",
        "  print('Gender Bias female word for ' + word[0] + ' is: ' + complete_analogy('man', word[0], 'woman', word_to_vec_map))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "after Debiasing\n",
            "Gender Bias female word for father is: brother\n",
            "Gender Bias female word for uncle is: cousin\n",
            "Gender Bias female word for brother is: cousin\n",
            "Gender Bias female word for brothers is: sons\n",
            "Gender Bias female word for grandfather is: grandson\n",
            "Gender Bias female word for schoolboy is: schoolgirl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BpfygNZBDQ7Z"
      },
      "source": [
        "States & Captial Debiasing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oKlCT7OoDQ7c",
        "colab": {}
      },
      "source": [
        "word_observations = ['rajasthan', 'maharashtra', 'karnataka','kerala', 'gujarat', 'bihar', 'orissa']\n",
        "matching = ['telangana', 'hyderabad']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6bece18a-8ad4-43ba-db2a-d5dace30e5c9",
        "id": "X8g0WiFIDQ7j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print('before Debiasing')\n",
        "for word in word_observations:\n",
        "  print('Gender Bias female word for ' + word + ' is: ' + complete_analogy(matching[0], matching[1], word, word_to_vec_map))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before Debiasing\n",
            "Gender Bias female word for rajasthan is: bangalore\n",
            "Gender Bias female word for maharashtra is: bangalore\n",
            "Gender Bias female word for karnataka is: bangalore\n",
            "Gender Bias female word for kerala is: bangalore\n",
            "Gender Bias female word for gujarat is: mumbai\n",
            "Gender Bias female word for bihar is: bangalore\n",
            "Gender Bias female word for orissa is: bangalore\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f1803034-cc8c-4716-d45f-88bc43f954a8",
        "id": "zoi8qkLpDQ70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "\n",
        "print('after Debiasing')\n",
        "words = [['rajasthan', 'jaipur'], ['maharashtra', 'mumbai'], ['karnataka', 'bangalore'], ['gujarat', 'gandhinagar'], ['bihar', 'patna'], ['orissa', 'bhubaneswar']]\n",
        "for word in words:\n",
        "  e1, e2 = equalize((word[0], word[1]), word_to_vec_map['hyderabad'] - word_to_vec_map['telangana'], word_to_vec_map)\n",
        "  word_to_vec_map[word[0]] = e1\n",
        "  word_to_vec_map[word[1]] = e2\n",
        "  print('Capital of ' + word[0] + ' is: ' + complete_analogy('telangana', 'hyderabad', word[0], word_to_vec_map))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "after Debiasing\n",
            "Capital of rajasthan is: jaipur\n",
            "Capital of maharashtra is: mumbai\n",
            "Capital of karnataka is: bangalore\n",
            "Capital of gujarat is: gandhinagar\n",
            "Capital of bihar is: patna\n",
            "Capital of orissa is: bhubaneswar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxXzzZFjHz1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rpfL2yqIH0J-"
      },
      "source": [
        "Language Debiasing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wfg8THmzH0KA",
        "colab": {}
      },
      "source": [
        "word_observations = ['rajasthan', 'maharashtra', 'karnataka','kerala', 'gujarat', 'bihar', 'orissa']\n",
        "matching = ['telangana', 'telugu']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "95516102-de41-4d32-ee53-95fc48b75c65",
        "id": "OO4fw-s9H0KE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print('before Debiasing')\n",
        "for word in word_observations:\n",
        "  print('Gender Bias female word for ' + word + ' is: ' + complete_analogy(matching[0], matching[1], word, word_to_vec_map))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before Debiasing\n",
            "Gender Bias female word for rajasthan is: kannada\n",
            "Gender Bias female word for maharashtra is: malayalam\n",
            "Gender Bias female word for karnataka is: malayalam\n",
            "Gender Bias female word for kerala is: kannada\n",
            "Gender Bias female word for gujarat is: malayalam\n",
            "Gender Bias female word for bihar is: malayalam\n",
            "Gender Bias female word for orissa is: malayalam\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9c6c0921-2097-43f2-813c-2a5b3f81cb64",
        "id": "O9Sme4BsH0KI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "\n",
        "print('after Debiasing')\n",
        "words = [['rajasthan', 'rajasthani'], ['maharashtra', 'marathi'], ['karnataka', 'kannada'], ['gujarat', 'gujarati'], ['bihar', 'hindi'], ['kerala', 'malayalam'], ['orissa', 'oriya']]\n",
        "for word in words:\n",
        "  e1, e2 = equalize((word[0], word[1]), word_to_vec_map['telugu'] - word_to_vec_map['telangana'], word_to_vec_map)\n",
        "  word_to_vec_map[word[0]] = e1\n",
        "  word_to_vec_map[word[1]] = e2\n",
        "  print('Capital of ' + word[0] + ' is: ' + complete_analogy('telangana', 'telugu', word[0], word_to_vec_map))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "after Debiasing\n",
            "Capital of rajasthan is: rajasthani\n",
            "Capital of maharashtra is: marathi\n",
            "Capital of karnataka is: kannada\n",
            "Capital of gujarat is: gujarati\n",
            "Capital of bihar is: hindi\n",
            "Capital of kerala is: malayalam\n",
            "Capital of orissa is: oriya\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzYCIyG5K026",
        "colab_type": "text"
      },
      "source": [
        "Verifying Doctor Resumes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfl8ZYdVNvXZ",
        "colab_type": "code",
        "outputId": "68f43e1b-b7f0-4140-ca7c-f3d5be4944c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import itertools\n",
        "import nltk\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "nltk.download('stopwords'),nltk.download('porter_test'), nltk.download('punkt'), nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]   Package porter_test is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True, True, True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwu9o_KbKE-i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "male_resume = 'John is a passionate doctor with extensive experience in internal medicine and hospital settings. Adpat in properly diagnosing and strategizing for the best treatment plans for patients. Jhon is experienced in counseling patients on preventative care and positive life style changes. Bringing forth an empathetic and professional attitude, committed to providing patients with the best care possible'\n",
        "female_resume = 'Mary is a passionate doctor with extensive experience in internal medicine and hospital settings. Adpat in properly diagnosing and strategizing for the best treatment plans for patients. Mary is experienced in counseling patients on preventative care and positive life style changes.'\n",
        "\n",
        "stopset = set(stopwords.words('english'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RW5jgidSviGS",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "vectoriser = TfidfVectorizer(stop_words = None, use_idf=True, ngram_range=(1,3), decode_error=\"ignore\")\n",
        "X = vectoriser.fit_transform(list(male_resume))\n",
        "\n",
        "'''from sklearn.decomposition import TruncatedSVD\n",
        "lsa = TruncatedSVD(n_components = 20, n_iter = 100)\n",
        "lsa.fit(X)'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRaohmyRM1qf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "terms = vectoriser.get_feature_names()\n",
        "for i, comp in enumerate(lsa.components_):\n",
        "  termsinComp = zip(terms, comp)\n",
        "  sortedTerms = sorted(termsinComp, key = lambda x:x[1], reverse=True)[:20]\n",
        "  print(\"article \" + str(i) + \":\")\n",
        "  for term in sortedTerms:\n",
        "    print(term)\n",
        "  print(\" \")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}